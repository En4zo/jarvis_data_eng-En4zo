# Hadoop Project
## Introduction
### Purpose of this project
  The primary objective of this project, as outlined in the project kick-off ticket, is to explore and evaluate the capabilities of Hadoop and its ecosystem, specifically focusing on Apache Hive, in addressing and solving complex business problems. By leveraging the power of Hadoop clusters and distributed computing, we aim to efficiently process large-scale data and extract valuable insights.
  
### Learnings and Evaluations
Throughout the course of this project, we have learned and evaluated various core Hadoop components, such as MapReduce, HDFS, and YARN. We provisioned a Hadoop cluster on Google Cloud Platform (GCP) using Dataproc, which allowed us to seamlessly manage and scale our resources as needed.

### Hadoop Cluster, Tools, and the Hive Project
We utilized Apache Hive and the Zeppelin Notebook to address specific business problems, practicing various HiveQL queries and comparing the efficiency of different methodologies. Some of the techniques we used include:

- Querying with and without cache to determine performance differences
- Evaluating partitioned vs non-partitioned queries to optimize data retrieval
- Resolving parsing issues using CSV SerDe for improved data handling
- Optimizing data storage and access by implementing columnar file formats


## Hadoop Cluster
- cluster architecture diagram
    - 1 master and 2 workers nodes
    - HDFS, YARN, Zeppelin, Hive (hive Server, hive metastore, RDBMS), etc.
- Big data tools you evaluated (e.g. MapReduce, YARN, HDFS, Hive, Zeppelin, etc..)
- hardware specifications

## Hive Project
- Discuss how you optimized Hive queries? (e.g. partitions, columnar, etc..)
- Post your Zeppelin Notebook screenshot here
    - Make sure your Notebook is nice and clean as hiring managers will visit your project
    - use `Full Page Screen Capture` chrome extension to capture a webpage as a picture

## Improvements
- at least three improvements